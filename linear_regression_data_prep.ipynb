{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "homedir='/media/raghuram/My Passport/dicom_seg/TCGA-LGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(homedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_file_params_df=pd.read_csv('dicom_file_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24398, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicom_file_params_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_post_samples_df = pd.read_csv('t1_post_samples.csv')\n",
    "t1_pre_samples_df = pd.read_csv('t1_pre_samples.csv')\n",
    "flair_samples = pd.read_csv('flair_samples.csv')\n",
    "t2_pre_samples = pd.read_csv('t2_pre_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       AXIAL T1 POST GAD FATSAT\n",
       "1        BRAIN_CONTRAST/T1_AXIAL\n",
       "2               T1 AX SE FS POST\n",
       "3            AX T1 POST GD FLAIR\n",
       "4             POST AX T1W_IR_TSE\n",
       "5          AXIAL T1 FSE POST GAD\n",
       "6               POST AX T1 FLAIR\n",
       "7            MRHR T1 AX POST GAD\n",
       "8                    T1 AXIAL GD\n",
       "9            AX T1 MP SPGR + GAD\n",
       "10                 POST AX T1 SE\n",
       "11               AX T1 MP SPGR+C\n",
       "12            POST AX T1 MP SPGR\n",
       "13           VOLUMETRIC AXIAL GD\n",
       "14               POST AX 3D SPGR\n",
       "15                  AX 3D SPGR+C\n",
       "16              +C AX T1 MP SPGR\n",
       "17                  C+AX 3D SPGR\n",
       "18                       AX T1+C\n",
       "19                AX 3D SPGR + C\n",
       "20                    AX T1 SE+C\n",
       "21           RA ROUTINE T1 AX +C\n",
       "22       +C 3D AXIAL IRSPGR FAST\n",
       "23              AX T1 MP SPGR +C\n",
       "24                 +C AX 3D SPGR\n",
       "25    BRAIN_CONTRAST/T1_AXIAL_C+\n",
       "Name: Sequence Name, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_post_samples_df['Sequence Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_mapper_dict = {'T1CE':t1_post_samples_df.values,\n",
    "               'T1W':t1_pre_samples_df.values,\n",
    "               'T2W': t2_pre_samples.values,\n",
    "               'T2F': flair_samples.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_sequence = []\n",
    "for idx, row in dicom_file_params_df.iterrows():\n",
    "    try:\n",
    "        if row['scanning_seq_mri'] in sequence_mapper_dict['T1CE']:\n",
    "            mapped_sequence.append('T1CE')\n",
    "        elif row['scanning_seq_mri'] in sequence_mapper_dict['T1W']:\n",
    "            mapped_sequence.append('T1W')\n",
    "        elif row['scanning_seq_mri'] in sequence_mapper_dict['T2W']:\n",
    "            mapped_sequence.append('T2W')\n",
    "        elif row['scanning_seq_mri'] in sequence_mapper_dict['T2F']:\n",
    "            mapped_sequence.append('T2F')\n",
    "    except Exception as e:\n",
    "        print('{}, {} in row {}'.format(e, row['scanning_seq_mri'], idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24398"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_file_params_df['mat_file_sequence'] = mapped_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_file_params_df.to_csv('dicom_file_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

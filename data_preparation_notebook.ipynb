{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd '/home/raghuram/Desktop/radiomics/STUDIES/LGG_study/WORKSPACE/TCGA_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAIR_data = loadmat('T2Fpath.mat')\n",
    "T1W_data = loadmat('T1Wpath.mat')\n",
    "T1CE_data = loadmat('T1CEpath.mat')\n",
    "T2W_data = loadmat('T2Wpath.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/media/raghuram/My Passport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydicom import dcmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_path = [FLAIR_data['T2Fpath'], T1W_data['T1Wpath'],\n",
    "               T1CE_data['T1CEpath'], T2W_data['T2Wpath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1ce_path = T1CE_data['T1CEpath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_path = FLAIR_data['T2Fpath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2w_path = T2W_data['T2Wpath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1w_path = T1W_data['T1Wpath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('mapped_files_to_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sequence_name'] == 'T1CE'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_magnetic_strength(data):\n",
    "    \n",
    "    try:\n",
    "        mag_field_strength = data.MagneticFieldStrength\n",
    "        if mag_field_strength > 1000:\n",
    "            mag_field_strength /= 10000\n",
    "        return mag_field_strength\n",
    "    \n",
    "    except Exception:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_patient_name(filename):\n",
    "    try:\n",
    "        return filename.split('/')[6]\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scanner_model_name(data):\n",
    "    try:\n",
    "        return data.ManufacturerModelName\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scanner_model_manufacturer(data):\n",
    "    try:\n",
    "        return data.Manufacturer\n",
    "    except: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sequence_name(seriesinstanceUID):\n",
    "    try:\n",
    "        return sequence_dict.get(seriesinstanceUID, 'NA')\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_seriesinstance_uid(data):\n",
    "    try:\n",
    "        return data.SeriesInstanceUID\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_flip_angle(data):\n",
    "    try:\n",
    "        return data.FlipAngle\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_inversion_time(data):\n",
    "    try:\n",
    "        return data.InversionTime\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_repetition_time(data):\n",
    "    try:\n",
    "        return data.RepetitionTime\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_excitation_time(data):\n",
    "    try:\n",
    "        return data.EchoTime\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_name = []\n",
    "magnetic_strength_list = []\n",
    "scanner_model_list = []\n",
    "scanner_manufacturer_list = []\n",
    "patient_list = []\n",
    "series_list = []\n",
    "flip_angle_list = []\n",
    "repetition_time = []\n",
    "excitation_time = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index%1000 == 0:\n",
    "        print('{} entries processed'.format(index+1))\n",
    "    try:\n",
    "        data = dcmread(row['filename'])\n",
    "        scanner_model_list.append(fetch_scanner_model_name(data))\n",
    "        scanner_manufacturer_list.append(fetch_scanner_model_manufacturer(data))\n",
    "        patient_list.append(fetch_patient_name(row['filename']))\n",
    "        magnetic_strength_list.append(fetch_magnetic_strength(data))\n",
    "        series_list.append(fetch_seriesinstance_uid(data))\n",
    "        sequence_name.append(fetch_sequence_name(data.SeriesInstanceUID))\n",
    "        flip_angle_list.append(fetch_flip_angle(data))\n",
    "        repetition_time.append(fetch_repetition_time(data))\n",
    "        excitation_time.append(fetch_excitation_time(data))\n",
    "    except Exception as e:\n",
    "        print('Error {} at index {}'.format(e, index))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seriesinstanceuid'] = series_list\n",
    "df['scanner_model'] = scanner_model_list\n",
    "df['scanner_manufacturer'] = scanner_manufacturer_list\n",
    "df['flip_angle'] = flip_angle_list\n",
    "df['patient_name'] = patient_list\n",
    "df['mag_field_strength'] = magnetic_strength_list\n",
    "df['sequence_name'] = sequence_name\n",
    "df['repetition_time'] = repetition_time\n",
    "df['excitation_time'] = excitation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'General Electric':'GE', 'GE MEDICAL SYSTEMS':'GE', 'SIEMENS':'Siemens', 'Philips Healthcare': 'Philips', \n",
    "           'Philips Medical Systems': 'Philips'}, inplace=True)\n",
    "df = df[df['scanner_manufacturer'] != 'Hitachi Medical Corporation']\n",
    "df['mat_file_name'] = df['patient_name']+'_'+df['sequence_name']+'.mat'\n",
    "# df.drop(columns=['filename', 'seriesinstanceuid'], inplace=True)\n",
    "df.to_csv('mapped_files_to_sequences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/media/raghuram/My Passport')\n",
    "import pandas as pd\n",
    "df = pd.read_csv('mapped_files_to_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_T1CE = df[df['sequence_name'] == 'T1CE']\n",
    "T1CE_files = list(df_T1CE['mat_file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/raghuram/Desktop/radiomics/TEXTURES/mat_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1CE_mat_list = glob.glob('*_T1CE.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flatten_features(data, filename):\n",
    "    \n",
    "    features_flattened = []\n",
    "    \n",
    "    for experiment_, values in data['textures']['List'].items():\n",
    "        \n",
    "        experiment_number = int(experiment_.split('Experiment')[1])\n",
    "        if experiment_number > 25:\n",
    "            break\n",
    "        scale_ = float(values.split(',')[0].split('=')[1])\n",
    "        algo_ = values.split(',')[1].split('=')[1]\n",
    "        ng_ = int(values.split(',')[2].split('=')[1])\n",
    "        \n",
    "        flattened_df = pd.io.json.json_normalize(data['textures'][experiment_], sep='_')\n",
    "        flattened_df['mat_file_name'] = filename\n",
    "        flattened_df_merged = pd.merge(flattened_df, df, on='mat_file_name', how='inner')\n",
    "        flattened_df_merged['experiment_number'] = experiment_number\n",
    "        flattened_df_merged['scale'] = scale_\n",
    "        flattened_df_merged['algo'] = algo_\n",
    "        flattened_df_merged['ng'] = ng_\n",
    "        features_flattened.append(flattened_df_merged)\n",
    "    \n",
    "    features_df_concat = pd.concat(features_flattened, ignore_index=True)\n",
    "    features_df_concat.to_csv(filename.split('.')[0]+'_features'+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_texture_csv(sequence_mat_list, sequence_file_list):\n",
    "    common_files = set(sequence_file_list).intersection(set(sequence_mat_list))\n",
    "    print(len(common_files))\n",
    "    for idx, mat_file in enumerate(common_files):\n",
    "        print('Processing file number {}'.format(idx+1))\n",
    "        data = loadmat(mat_file)\n",
    "        extract_flatten_features(data, mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_texture_csv(T1CE_mat_list, T1CE_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1ce_files = glob.glob('*_T1CE_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for t1ce_file in t2f_files:\n",
    "    df = pd.read_csv(t1ce_file)\n",
    "    df['Tumor'] = df['patient_name']\n",
    "    df.drop(columns=['filename', 'seriesinstanceuid', 'patient_name', 'parameters_Algo', 'parameters_Scale',\n",
    "                    'parameters_Ng'], inplace=True)\n",
    "    df_list.append(df)\n",
    "\n",
    "pd.concat(df_list).to_csv(os.path.join('/home/raghuram/Desktop/radiomics/TEXTURES', 'expt_t1ce.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/raghuram/Desktop/radiomics/TEXTURES/mat_folder\n"
     ]
    }
   ],
   "source": [
    "cd /home/raghuram/Desktop/radiomics/TEXTURES/mat_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "T1CE_mat_file = glob.glob('*_T1CE.mat')\n",
    "T1W_mat_file = glob.glob('*_T1W.mat')\n",
    "T2W_mat_file = glob.glob('*_T2W.mat')\n",
    "T2F_mat_file = glob.glob('*_T2F.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gft_folder = '/home/raghuram/Desktop/radiomics/TEXTURES/graph_fourier_transform/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flatten_features(data_list):\n",
    "    \n",
    "    features_flattened = []\n",
    "    for mat_file in data_list:\n",
    "        data = loadmat(mat_file)\n",
    "        for experiment_, values in data['textures']['List'].items():\n",
    "\n",
    "            experiment_number = int(experiment_.split('Experiment')[1])\n",
    "            if experiment_number > 25:\n",
    "                break\n",
    "            scale_ = float(values.split(',')[0].split('=')[1])\n",
    "            algo_ = values.split(',')[1].split('=')[1]\n",
    "            ng_ = int(values.split(',')[2].split('=')[1])\n",
    "\n",
    "            flattened_df = pd.io.json.json_normalize(data['textures'][experiment_], sep='_')\n",
    "            features_flattened.append(flattened_df)\n",
    "            flattened_df['mat_file_name'] = mat_file\n",
    "            flattened_df['experiment_number'] = experiment_number\n",
    "        \n",
    "    features_df_concat = pd.concat(features_flattened, ignore_index=True)    \n",
    "    \n",
    "    return features_df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('t1ce_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
